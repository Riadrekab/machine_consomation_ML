{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# total = 0\n",
    "# for i in range(2,7):\n",
    "#     dfY = pd.read_csv(\"StepOne_LabelTrain.csv\").iloc[:,i].to_numpy()\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(dfX, dfY)\n",
    "#     from sklearn.dummy import DummyClassifier\n",
    "#     classifier = DummyClassifier(strategy=\"prior\")\n",
    "#     classifier.fit(X_train, y_train)\n",
    "#     total += classifier.score(X_test, y_test)\n",
    "# print(total/5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeStep_0</th>\n",
       "      <th>TimeStep_1</th>\n",
       "      <th>TimeStep_2</th>\n",
       "      <th>TimeStep_3</th>\n",
       "      <th>TimeStep_4</th>\n",
       "      <th>TimeStep_5</th>\n",
       "      <th>TimeStep_6</th>\n",
       "      <th>TimeStep_7</th>\n",
       "      <th>TimeStep_8</th>\n",
       "      <th>TimeStep_9</th>\n",
       "      <th>...</th>\n",
       "      <th>TimeStep_2150</th>\n",
       "      <th>TimeStep_2151</th>\n",
       "      <th>TimeStep_2152</th>\n",
       "      <th>TimeStep_2153</th>\n",
       "      <th>TimeStep_2154</th>\n",
       "      <th>TimeStep_2155</th>\n",
       "      <th>TimeStep_2156</th>\n",
       "      <th>TimeStep_2157</th>\n",
       "      <th>TimeStep_2158</th>\n",
       "      <th>TimeStep_2159</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>181.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>...</td>\n",
       "      <td>238.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>238.333333</td>\n",
       "      <td>238.333333</td>\n",
       "      <td>236.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>235.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2437.000000</td>\n",
       "      <td>2426.0</td>\n",
       "      <td>2148.0</td>\n",
       "      <td>645.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>2256.666667</td>\n",
       "      <td>2436.0</td>\n",
       "      <td>2436.0</td>\n",
       "      <td>2212.0</td>\n",
       "      <td>...</td>\n",
       "      <td>235.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>234.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232.000000</td>\n",
       "      <td>232.0</td>\n",
       "      <td>232.5</td>\n",
       "      <td>233.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>233.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>...</td>\n",
       "      <td>185.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>181.500000</td>\n",
       "      <td>181.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180.333333</td>\n",
       "      <td>181.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>184.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>...</td>\n",
       "      <td>357.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>358.000000</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>348.5</td>\n",
       "      <td>340.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>344.000000</td>\n",
       "      <td>341.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>313.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>...</td>\n",
       "      <td>235.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>233.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10416</th>\n",
       "      <td>275.000000</td>\n",
       "      <td>272.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>268.5</td>\n",
       "      <td>270.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>...</td>\n",
       "      <td>281.0</td>\n",
       "      <td>282.5</td>\n",
       "      <td>278.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>278.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>281.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10417</th>\n",
       "      <td>279.000000</td>\n",
       "      <td>283.5</td>\n",
       "      <td>281.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>281.5</td>\n",
       "      <td>283.000000</td>\n",
       "      <td>284.5</td>\n",
       "      <td>281.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>...</td>\n",
       "      <td>231.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>230.5</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>230.0</td>\n",
       "      <td>230.5</td>\n",
       "      <td>231.0</td>\n",
       "      <td>231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10418</th>\n",
       "      <td>229.000000</td>\n",
       "      <td>229.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>229.500000</td>\n",
       "      <td>230.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>...</td>\n",
       "      <td>231.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>231.5</td>\n",
       "      <td>231.0</td>\n",
       "      <td>230.5</td>\n",
       "      <td>231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10419</th>\n",
       "      <td>250.000000</td>\n",
       "      <td>247.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>246.5</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>249.5</td>\n",
       "      <td>249.0</td>\n",
       "      <td>247.5</td>\n",
       "      <td>...</td>\n",
       "      <td>250.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>246.500000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>249.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10420</th>\n",
       "      <td>249.000000</td>\n",
       "      <td>250.0</td>\n",
       "      <td>246.5</td>\n",
       "      <td>249.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>246.0</td>\n",
       "      <td>248.5</td>\n",
       "      <td>247.0</td>\n",
       "      <td>...</td>\n",
       "      <td>424.0</td>\n",
       "      <td>371.5</td>\n",
       "      <td>364.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>378.000000</td>\n",
       "      <td>366.500000</td>\n",
       "      <td>376.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>361.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10421 rows × 2160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TimeStep_0  TimeStep_1  TimeStep_2  TimeStep_3  TimeStep_4  \\\n",
       "0       180.000000       180.0       180.0       181.0       180.0   \n",
       "1      2437.000000      2426.0      2148.0       645.0       642.0   \n",
       "2       232.000000       232.0       232.5       233.0       233.0   \n",
       "3       180.333333       181.0       180.0       184.0       181.0   \n",
       "4       344.000000       341.0       341.0       327.0       327.0   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "10416   275.000000       272.0       270.0       275.0       269.0   \n",
       "10417   279.000000       283.5       281.0       281.0       277.0   \n",
       "10418   229.000000       229.0       231.0       231.0       230.0   \n",
       "10419   250.000000       247.0       247.0       249.0       246.0   \n",
       "10420   249.000000       250.0       246.5       249.0       249.0   \n",
       "\n",
       "       TimeStep_5   TimeStep_6  TimeStep_7  TimeStep_8  TimeStep_9  ...  \\\n",
       "0           180.0   180.000000       181.0       180.0       181.0  ...   \n",
       "1           642.0  2256.666667      2436.0      2436.0      2212.0  ...   \n",
       "2           234.0   233.000000       233.0       232.0       234.0  ...   \n",
       "3           180.0   183.000000       184.0       184.0       183.0  ...   \n",
       "4           318.0   318.000000       313.0       313.0       315.0  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "10416       267.0   269.000000       268.5       270.0       285.0  ...   \n",
       "10417       281.5   283.000000       284.5       281.0       281.0  ...   \n",
       "10418       230.0   229.500000       230.0       231.0       231.0  ...   \n",
       "10419       246.5   246.000000       249.5       249.0       247.5  ...   \n",
       "10420       247.0   247.000000       246.0       248.5       247.0  ...   \n",
       "\n",
       "       TimeStep_2150  TimeStep_2151  TimeStep_2152  TimeStep_2153  \\\n",
       "0              238.0          238.0          238.0          236.0   \n",
       "1              235.0          233.0          233.0          236.0   \n",
       "2              185.0          182.0          181.0          180.0   \n",
       "3              357.0          351.0          349.0          351.0   \n",
       "4              235.0          238.0          238.0          235.0   \n",
       "...              ...            ...            ...            ...   \n",
       "10416          281.0          282.5          278.0          278.0   \n",
       "10417          231.0          230.0          231.0          230.5   \n",
       "10418          231.0          231.0          234.0          231.0   \n",
       "10419          250.0          249.0          247.0          247.0   \n",
       "10420          424.0          371.5          364.0          375.0   \n",
       "\n",
       "       TimeStep_2154  TimeStep_2155  TimeStep_2156  TimeStep_2157  \\\n",
       "0         238.333333     238.333333          236.0          234.0   \n",
       "1         236.000000     236.000000          234.0          234.0   \n",
       "2         182.000000     181.500000          181.0          180.0   \n",
       "3         358.000000     349.000000          348.5          340.0   \n",
       "4         235.000000     235.000000          233.0          233.0   \n",
       "...              ...            ...            ...            ...   \n",
       "10416     278.000000     280.000000          281.0          280.0   \n",
       "10417     231.000000     230.000000          230.0          230.5   \n",
       "10418     233.000000     231.000000          231.5          231.0   \n",
       "10419     246.500000     249.000000          249.0          247.0   \n",
       "10420     378.000000     366.500000          376.0          367.0   \n",
       "\n",
       "       TimeStep_2158  TimeStep_2159  \n",
       "0              234.0          235.0  \n",
       "1              230.0          233.0  \n",
       "2              180.0          180.0  \n",
       "3              346.0          344.0  \n",
       "4              235.0          233.0  \n",
       "...              ...            ...  \n",
       "10416          280.0          281.0  \n",
       "10417          231.0          231.0  \n",
       "10418          230.5          231.0  \n",
       "10419          248.0          250.0  \n",
       "10420          353.0          361.0  \n",
       "\n",
       "[10421 rows x 2160 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# dfX['WaveletVar'] = dfX['WaveletVar'].map(lambda x:  round(x,2))\n",
    "\n",
    "\n",
    "\n",
    "dfX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8346124328472755  Column number : 1\n",
      "0.896392939370683  Column number : 2\n",
      "0.9574059861857253  Column number : 3\n",
      "0.8484267075978511  Column number : 4\n",
      "0.8511128165771297  Column number : 5\n",
      "0.8775901765157329\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "classifier = RandomForestClassifier(n_estimators=100)\n",
    "total =0\n",
    "for i in range(2,7):\n",
    "    dfY = pd.read_csv(\"StepOne_LabelTrain.csv\").iloc[:,i].to_numpy()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dfX, dfY)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    total += accuracy_score(y_test, y_pred)\n",
    "    print(accuracy_score(y_test, y_pred),' Column number :' , i-1)\n",
    "    \n",
    "print(total/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8265541059094398  Column number : 1\n",
      "0.9040675364543361  Column number : 2\n",
      "0.9639293937068304  Column number : 3\n",
      "0.851880276285495  Column number : 4\n",
      "0.8514965464313123  Column number : 5\n",
      "0.8795855717574828\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "classifier = RandomForestClassifier(n_estimators=75)\n",
    "total =0\n",
    "for k in range(2,7):\n",
    "    dfY = pd.read_csv(\"StepOne_LabelTrain.csv\").iloc[:,k].to_numpy()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dfX, dfY)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    total += accuracy_score(y_test, y_pred)\n",
    "    print(accuracy_score(y_test, y_pred),' Column number :' , k-1)\n",
    "print(total/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = RandomForestClassifier(n_estimators = 50)\n",
    "# listNames = [\"Washing Machine\",\"Dishwasher\",\"Tumble Dryer\",\"Microwave\",\"Kettle\"]\n",
    "# finalDf = pd. DataFrame()\n",
    "\n",
    "# for k in range(2,7):\n",
    "#     dfY = pd.read_csv(\"StepOne_LabelTrain.csv\").iloc[:,k].to_numpy()\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(dfX, dfY)\n",
    "#     classifier.fit(X_train, y_train)\n",
    "#     y_pred = classifier.predict(dfXTest)\n",
    "#     finalDf[listNames[k-2]]=pd.Series(y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2406\n",
       "1      82\n",
       "Name: Washing Machine, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finalDf = finalDf.rename_axis('Index')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [22509360, 10421]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m Y \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mStepOne_LabelTrain.csv\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39miloc[:,\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mto_numpy()\n\u001b[1;32m     36\u001b[0m knn \u001b[39m=\u001b[39m KNeighborsTimeSeriesClassifier(n_neighbors\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, Y)\n\u001b[1;32m     39\u001b[0m knn\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     40\u001b[0m y_pred \u001b[39m=\u001b[39m knn\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2559\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2556\u001b[0m \u001b[39mif\u001b[39;00m n_arrays \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAt least one array required as input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2559\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39;49marrays)\n\u001b[1;32m   2561\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[1;32m   2562\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m\n\u001b[1;32m   2564\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:443\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \n\u001b[1;32m    426\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    442\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[0;32m--> 443\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[1;32m    444\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [22509360, 10421]"
     ]
    }
   ],
   "source": [
    "# # from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "# # import pandas as pd\n",
    "# # import numpy as np\n",
    "\n",
    "# # # load your 20 columns pandas dataset as X_train and your 5 columns pandas dataset as y_train\n",
    "# # X_train = pd.read_csv(\"InputTrain.csv\").iloc[:,2:]\n",
    "# # # reshape X_train to be a list of time series data\n",
    "# # X_train = [X_train.iloc[:, i].values.reshape(-1, 1) for i in range(X_train.shape[1])]\n",
    "# # X_train = np.concatenate(X_train, axis=1)\n",
    "\n",
    "# # # convert y_train to a numpy array\n",
    "# # y_train = pd.read_csv('StepOne_LabelTrain.csv').iloc[:,2]\n",
    "# # y_train = y_train.values\n",
    "# # # create the KNN classifier with k=1\n",
    "# # knn = KNeighborsTimeSeriesClassifier(n_neighbors=1)\n",
    "\n",
    "# # # fit the classifier to the training data\n",
    "# # knn.fit(X_train, y_train)\n",
    "\n",
    "# # # make predictions on new data\n",
    "# # # reshape your new data (X_test) in the same way as X_train\n",
    "# # X_test = pd.read_csv(\"InputTest.csv\").iloc[:,2:]\n",
    "# # X_test = [X_test.iloc[:, i].values.reshape(-1, 1) for i in range(X_test.shape[1])]\n",
    "# # X_test = np.concatenate(X_test, axis=1)\n",
    "# # y_pred = knn.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "\n",
    "# dfX = pd.read_csv(\"InputTrain.csv\").iloc[:,2:]\n",
    "# # melt the dataframe to create a new dataframe with one column\n",
    "# new_df = pd.melt(dfX)\n",
    "# X = new_df[\"value\"].values\n",
    "# Y = pd.read_csv(\"StepOne_LabelTrain.csv\").iloc[:,2].to_numpy()\n",
    "# knn = KNeighborsTimeSeriesClassifier(n_neighbors=1)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y)\n",
    "\n",
    "# knn.fit(X_train, y_train)\n",
    "# y_pred = knn.predict(X_test)\n",
    "# accuracy = knn.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.datasets import load_arrow_head\n",
    "# transformers in scikit-learn maybe the solution to this \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.datasets import load_arrow_head\n",
    "# transformers in scikit-learn maybe the solution to this \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2488, 2160)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import re\n",
    "import pywt\n",
    "\n",
    "X = pd.read_csv(\"InputTrain.csv\").iloc[:,2:]\n",
    "y = pd.read_csv(\"StepOne_LabelTrain.csv\").iloc[:,2:]\n",
    "dfXTest = pd.read_csv(\"InputTest.csv\").iloc[:,2:]\n",
    "#l'ajout manuel des features prend un peu de temps c'est pas opti, ~50sec pour la cellule entière\n",
    "\n",
    "# Ajout manuel de 3 features (qui utilisent des Series et pas le dataframe entier)\n",
    "autocor = []\n",
    "idmax = []\n",
    "entropy = []\n",
    "for i in range(0,10421) :\n",
    "  autocor.append(X.iloc[i,0:2161].autocorr(216))\n",
    "  idmax.append((int)(re.search(r'\\d+',X.iloc[i,0:2161].idxmax())[0]))\n",
    "  entropy.append(sum([ p * math.log(p) / math.log(2.0) for p in X.iloc[i,0:2161]]))\n",
    "# X['autocor'] = autocor\n",
    "X['idmax'] = idmax\n",
    "X['entropy'] = entropy\n",
    "autocor = []\n",
    "idmax = []\n",
    "entropy = []\n",
    "print(dfXTest.shape)\n",
    "for i in range(0,2488) :\n",
    "  autocor.append(dfXTest.iloc[i,0:2161].autocorr(216))\n",
    "  idmax.append((int)(re.search(r'\\d+',dfXTest.iloc[i,0:2161].idxmax())[0]))\n",
    "  entropy.append(sum([ p * math.log(p) / math.log(2.0) for p in dfXTest.iloc[i,0:2161]]))\n",
    "# dfXTest['autocor'] = autocor\n",
    "dfXTest['idmax'] = idmax\n",
    "dfXTest['entropy'] = entropy\n",
    "\n",
    "\n",
    "# Ajout automatique de 6 features (qui utilisent le dataframe entier)\n",
    "X['mean'] = X.iloc[:, 2:2161].mean(axis=1)\n",
    "\n",
    "X['median'] = X.iloc[:, 2:2161].median(axis=1)\n",
    "\n",
    "X['std'] = X.iloc[:, 2:2161].std(axis=1)\n",
    "\n",
    "X['var'] = X.iloc[:, 2:2161].var(axis=1)\n",
    "\n",
    "X['skew'] = X.iloc[:, 2:2161].skew(axis=1)\n",
    "\n",
    "X['sem'] = X.iloc[:, 2:2161].sem(axis=1)\n",
    "\n",
    "\n",
    "dfXTest['mean'] = dfXTest.iloc[:, 2:2161].mean(axis=1)\n",
    "\n",
    "dfXTest['median'] = dfXTest.iloc[:, 2:2161].median(axis=1)\n",
    "\n",
    "dfXTest['std'] = dfXTest.iloc[:, 2:2161].std(axis=1)\n",
    "\n",
    "dfXTest['var'] = dfXTest.iloc[:, 2:2161].var(axis=1)\n",
    "\n",
    "dfXTest['skew'] = dfXTest.iloc[:, 2:2161].skew(axis=1)\n",
    "\n",
    "dfXTest['sem'] = dfXTest.iloc[:, 2:2161].sem(axis=1)\n",
    "\n",
    "\n",
    "def wavelet_variance(row):\n",
    "    coeffs = pywt.wavedec(row, 'db4', level=5) # perform 5-level decomposition using db4 wavelet\n",
    "    variances = [c.var() for c in coeffs] # calculate the variances of each detail coefficient\n",
    "    \n",
    "    return sum(variances) # return the sum of variances\n",
    "\n",
    "X['WaveletVar'] = X.apply(wavelet_variance, axis=1)\n",
    "dfXTest['WaveletVar'] = dfXTest.apply(wavelet_variance, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# scaled_x = scaler.fit_transform(X)\n",
    "# scaled_T = scaler.fit_transform(dfXTest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.42286\teval-rmse:0.43974\n",
      "[1]\ttrain-rmse:0.36280\teval-rmse:0.39682\n",
      "[2]\ttrain-rmse:0.31510\teval-rmse:0.36568\n",
      "[3]\ttrain-rmse:0.27602\teval-rmse:0.34432\n",
      "[4]\ttrain-rmse:0.24436\teval-rmse:0.32921\n",
      "[5]\ttrain-rmse:0.21739\teval-rmse:0.31854\n",
      "[6]\ttrain-rmse:0.19466\teval-rmse:0.31107\n",
      "[7]\ttrain-rmse:0.17602\teval-rmse:0.30569\n",
      "[8]\ttrain-rmse:0.16061\teval-rmse:0.30180\n",
      "[9]\ttrain-rmse:0.14689\teval-rmse:0.29906\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train,y_train)\n",
    "dtest = xgb.DMatrix(X_test,y_test)\n",
    "\n",
    "model = xgb.XGBModel(n_estimators=10)\n",
    "params = {\n",
    "    'max_depth': 20,\n",
    "    'eta': 0.3,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'rmse',\n",
    "    'booster':'gbtree',\n",
    "    'subsample': 0.85,\n",
    "    'learning_rate':0.2,\n",
    "\n",
    "}\n",
    "\n",
    "# Train model\n",
    "evalist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "model = xgb.train(params, dtrain,evals=evalist)\n",
    "\n",
    "dFin = xgb.DMatrix(dfXTest)\n",
    "\n",
    "preds = model.predict(dFin) #Predictions\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfF = pd.DataFrame(preds, columns=[\"Washing Machine\",\"Dishwasher\",\"Tumble Dryer\",\"Microwave\",\"Kettle\"])\n",
    "dfF = dfF.rename_axis('Index')\n",
    "dfF.to_csv(\"oneT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8317920184190329\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# totF =0\n",
    "# for k in range (1,5) :\n",
    "#     dfX['std'] = dfX.iloc[:, 2:].std(axis=1)\n",
    "#     dfX['var'] = dfX.iloc[:, 2:].var(axis=1)\n",
    "#     total = 0\n",
    "\n",
    "#     for i in range(2,7):\n",
    "#         dfY = pd.read_csv(\"StepOne_LabelTrain.csv\").iloc[:,i].to_numpy()\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(dfX, dfY)\n",
    "#         classifier = DummyClassifier(strategy=\"prior\")\n",
    "#         classifier.fit(X_train, y_train)\n",
    "#         total += classifier.score(X_test, y_test)\n",
    "\n",
    "#     totF += total /5\n",
    "# print(totF/4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Washing Machine</th>\n",
       "      <th>Dishwasher</th>\n",
       "      <th>Tumble Dryer</th>\n",
       "      <th>Microwave</th>\n",
       "      <th>Kettle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.196328</td>\n",
       "      <td>0.155483</td>\n",
       "      <td>0.072301</td>\n",
       "      <td>0.170945</td>\n",
       "      <td>0.278544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.158500</td>\n",
       "      <td>0.265667</td>\n",
       "      <td>0.021269</td>\n",
       "      <td>0.106424</td>\n",
       "      <td>0.365963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.052177</td>\n",
       "      <td>0.043402</td>\n",
       "      <td>0.006387</td>\n",
       "      <td>0.056172</td>\n",
       "      <td>0.227191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.161630</td>\n",
       "      <td>0.136407</td>\n",
       "      <td>0.040873</td>\n",
       "      <td>0.139150</td>\n",
       "      <td>0.290110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.228074</td>\n",
       "      <td>0.159977</td>\n",
       "      <td>0.176064</td>\n",
       "      <td>0.239632</td>\n",
       "      <td>0.400129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>0.266665</td>\n",
       "      <td>0.185597</td>\n",
       "      <td>0.015363</td>\n",
       "      <td>0.181303</td>\n",
       "      <td>0.251275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>0.192667</td>\n",
       "      <td>0.160788</td>\n",
       "      <td>0.074388</td>\n",
       "      <td>0.180723</td>\n",
       "      <td>0.280159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>0.325879</td>\n",
       "      <td>0.309132</td>\n",
       "      <td>0.199683</td>\n",
       "      <td>0.301394</td>\n",
       "      <td>0.374529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>0.250574</td>\n",
       "      <td>0.226559</td>\n",
       "      <td>0.093387</td>\n",
       "      <td>0.164121</td>\n",
       "      <td>0.278832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>0.218751</td>\n",
       "      <td>0.210953</td>\n",
       "      <td>0.071784</td>\n",
       "      <td>0.183130</td>\n",
       "      <td>0.279202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2085 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Washing Machine  Dishwasher  Tumble Dryer  Microwave    Kettle\n",
       "0            0.196328    0.155483      0.072301   0.170945  0.278544\n",
       "1            0.158500    0.265667      0.021269   0.106424  0.365963\n",
       "2            0.052177    0.043402      0.006387   0.056172  0.227191\n",
       "3            0.161630    0.136407      0.040873   0.139150  0.290110\n",
       "4            0.228074    0.159977      0.176064   0.239632  0.400129\n",
       "...               ...         ...           ...        ...       ...\n",
       "2080         0.266665    0.185597      0.015363   0.181303  0.251275\n",
       "2081         0.192667    0.160788      0.074388   0.180723  0.280159\n",
       "2082         0.325879    0.309132      0.199683   0.301394  0.374529\n",
       "2083         0.250574    0.226559      0.093387   0.164121  0.278832\n",
       "2084         0.218751    0.210953      0.071784   0.183130  0.279202\n",
       "\n",
       "[2085 rows x 5 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.DataFrame(preds,columns=[\"Washing Machine\",\"Dishwasher\",\"Tumble Dryer\",\"Microwave\",\"Kettle\"])\n",
    "# y_test\n",
    "# # acc_rfc = (df == y_test).sum().astype(float) / len(preds)*100\n",
    "\n",
    "# # df.to_csv(\"XGB1.csv\")\n",
    "# # y_test\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Washing Machine</th>\n",
       "      <th>Dishwasher</th>\n",
       "      <th>Tumble Dryer</th>\n",
       "      <th>Microwave</th>\n",
       "      <th>Kettle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8233</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5860</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3911</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6246</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7035</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6663</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10409</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5878</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2085 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Washing Machine  Dishwasher  Tumble Dryer  Microwave  Kettle\n",
       "8233                 0           0             0          0       0\n",
       "5860                 0           0             0          0       0\n",
       "3463                 0           0             0          0       0\n",
       "3911                 0           0             0          0       1\n",
       "6246                 0           0             0          0       1\n",
       "...                ...         ...           ...        ...     ...\n",
       "7035                 0           0             0          0       0\n",
       "4207                 0           0             0          0       0\n",
       "6663                 0           0             0          0       0\n",
       "10409                1           0             0          0       0\n",
       "5878                 0           0             0          0       0\n",
       "\n",
       "[2085 rows x 5 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df.to_csv(\"XGB1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# create a DMATRIX from the training data\n",
    "\n",
    "# create an XGBoost model\n",
    "xgb_model = xgb.XGBModel()\n",
    "\n",
    "# train the model on the DMATRIX\n",
    "xgb_model.fit(dtrain)\n",
    "\n",
    "# use the model to make predictions on the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred\n",
    "preds\n",
    "df = pd.DataFrame(preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
