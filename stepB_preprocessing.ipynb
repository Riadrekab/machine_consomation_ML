{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Preprocessing these datasets in the correct formats is too time and resources consuming to do it on every execution, so we export the final dataframes to csv to reuse them directly elsewhere**"
      ],
      "metadata": {
        "id": "fEK79Pq6-hkt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQXXnrdit0y-",
        "outputId": "2808aa1c-eeed-42e2-e916-8468adbbe8ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n",
            "[Errno 107] Transport endpoint is not connected: 'gdrive/MyDrive/'\n",
            "/content/gdrive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive#On monte le drive pour charger les datasets depuis google drive (optionnel)\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "%cd gdrive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "X = pd.read_csv(\"/content/gdrive/MyDrive/M1 AI/Data Science/Project/step2/InputTrain.csv\").iloc[:,2:]\n",
        "Y1 = pd.read_csv(\"/content/gdrive/MyDrive/M1 AI/Data Science/Project/step2/StepTwo_LabelTrain_WashingMachine.csv\").iloc[:,2:]\n",
        "Y2 = pd.read_csv(\"/content/gdrive/MyDrive/M1 AI/Data Science/Project/step2/StepTwo_LabelTrain_Dishwasher.csv\").iloc[:,2:]\n",
        "Y3 = pd.read_csv(\"/content/gdrive/MyDrive/M1 AI/Data Science/Project/step2/StepTwo_LabelTrain_TumbleDryer.csv\").iloc[:,2:]\n",
        "Y4 = pd.read_csv(\"/content/gdrive/MyDrive/M1 AI/Data Science/Project/step2/StepTwo_LabelTrain_Microwave.csv\").iloc[:,2:]\n",
        "Y5 = pd.read_csv(\"/content/gdrive/MyDrive/M1 AI/Data Science/Project/step2/StepTwo_LabelTrain_Kettle.csv\").iloc[:,2:]\n",
        "dfXTest = pd.read_csv(\"/content/gdrive/MyDrive/M1 AI/Data Science/Project/step2/InputTest.csv\").iloc[:,2:]\n"
      ],
      "metadata": {
        "id": "bzq0cpRVt_Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "consumption_values = dfXTest.values\n",
        "consumption_values = consumption_values.reshape(consumption_values.shape[0], -1)\n",
        "\n",
        "# Remove the mean and scale the values to have unit variance\n",
        "scaler = StandardScaler()\n",
        "normalized_consumption_values = scaler.fit_transform(consumption_values)\n",
        "dfXTest.iloc[:, 0:] = normalized_consumption_values.reshape(normalized_consumption_values.shape[0], -1)\n"
      ],
      "metadata": {
        "id": "XGmPKRArB1Dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "consumption_values = X.values\n",
        "consumption_values = consumption_values.reshape(consumption_values.shape[0], -1)\n",
        "\n",
        "# Remove the mean and scale the values to have unit variance\n",
        "scaler = StandardScaler()\n",
        "normalized_consumption_values = scaler.fit_transform(consumption_values)\n",
        "X.iloc[:, 0:] = normalized_consumption_values.reshape(normalized_consumption_values.shape[0], -1)\n"
      ],
      "metadata": {
        "id": "-CJpJPdPtQqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y1 = Y1.melt().iloc[:,1]\n",
        "y2 = Y2.melt().iloc[:,1]\n",
        "y3 = Y3.melt().iloc[:,1]\n",
        "y4 = Y4.melt().iloc[:,1]\n",
        "y5 = Y5.melt().iloc[:,1]\n",
        "\n",
        "y= pd.DataFrame()\n",
        "y[\"Washing Machine\"] = y1\n",
        "y[\"Dishwasher\"] = y2\n",
        "y[\"Tumble Dryer\"] = y3\n",
        "y[\"Microwave\"] = y4\n",
        "y[\"Kettle\"] = y5\n",
        "\n",
        "\n",
        "\n",
        "import re\n",
        "def extract_numbers(text):\n",
        "    numbers = re.findall(r'\\d+', text)\n",
        "    return int(''.join(numbers))\n",
        "\n",
        "X = X.melt()\n",
        "X['variable'] = X['variable'].apply(extract_numbers)\n",
        "X = X.rename(columns={'variable': 'Serie_number'})\n",
        "lag_window = 3\n",
        "\n",
        "for i in range(1, lag_window+1):\n",
        "    X[f'lag_{i}'] = X['value'].shift(i)\n",
        "\n",
        "X['rolling_mean-3'] = X['value'].rolling(window=3).mean()\n",
        "X['rolling_mean-6'] = X['value'].rolling(window=6).mean()\n",
        "X['rolling_mean-6'] = X['value'].rolling(window=9).mean()\n",
        "\n",
        "\n",
        "\n",
        "# Drop rows with NaN values\n",
        "X.dropna(inplace=True)\n",
        "y = y.loc[X.index]\n",
        "\n",
        "dfXTest = dfXTest.melt()\n",
        "dfXTest['variable'] = dfXTest['variable'].apply(extract_numbers)\n",
        "dfXTest = dfXTest.rename(columns={'variable': 'Serie_number'})\n",
        "\n"
      ],
      "metadata": {
        "id": "THtr25iuyPFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.to_csv(\"/content/gdrive/MyDrive/M1 AI/Data Science/Project/step2/Melted_Train2.csv\", index=False)\n",
        "y.to_csv(\"/content/gdrive/MyDrive/M1 AI/Data Science/Project/step2/Melted_Fused_Labels3.csv\", index=False)\n",
        "dfXTest.to_csv(\"/content/gdrive/MyDrive/M1 AI/Data Science/Project/step2/Melted_Test2.csv\", index=False)"
      ],
      "metadata": {
        "id": "HraJdNbmOO47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import xgboost as xgb\n",
        "# from sklearn.metrics import average_precision_score\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.4,random_state=42)\n",
        "\n",
        "# dtrain = xgb.DMatrix(X_train,label=y_train)\n",
        "# dtest = xgb.DMatrix(X_test,label=y_test)\n",
        "\n",
        "# model = xgb.XGBModel()\n",
        "# params = {\n",
        "#     'max_depth': 10,\n",
        "#     'eta': 0.1,\n",
        "#     'objective': 'binary:logistic',\n",
        "#     'eval_metric': 'error',\n",
        "#     'booster':'dart',\n",
        "#     'sample_type':'weighted',\n",
        "#     'normalize_type':'forest',\n",
        "#     'learning_rate':0.4,\n",
        "#     'tree_method':'gpu_hist',\n",
        "#     'n_jobs':500,\n",
        "#     'rate_drop':0.3,\n",
        "#     'skip_drop':0.2,\n",
        "\n",
        "# }\n",
        "\n",
        "# # Train model\n",
        "# evalist = [(dtrain, 'train'), (dtest, 'eval')]\n",
        "# model = xgb.train(params, dtrain,num_boost_round=70,verbose_eval=1)\n",
        "\n",
        "# preds = model.predict(dtest) #Predictions\n",
        "# y_test = y_test.astype(float)\n",
        "# print(\"Precision = {}\".format(average_precision_score(y_test.values, preds, average='macro')))\n",
        "# print(\"Precision = {}\".format(average_precision_score(y_test.values, preds, average='weighted')))\n",
        "\n",
        "\n",
        "# #Precision = 0.25674527434942446 YANIS\n",
        "# #Precision = 0.4107742871167801 YANIS\n"
      ],
      "metadata": {
        "id": "kkOP8Bc9uY27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lag_window = 3\n",
        "\n",
        "# for i in range(1, lag_window+1):\n",
        "#     dfXTest[f'lag_{i}'] = dfXTest['value'].shift(i)\n",
        "\n",
        "# dfXTest['rolling_mean-3'] = dfXTest['value'].rolling(window=3).mean()\n",
        "# dfXTest['rolling_mean-6'] = dfXTest['value'].rolling(window=6).mean()\n",
        "\n",
        "\n",
        "# dFin = xgb.DMatrix(dfXTest)\n",
        "\n",
        "# preds_f = model.predict(dFin)\n",
        "\n",
        "# dfF = pd.DataFrame(preds_f, columns=[\"Washing Machine\",\"Dishwasher\",\"Tumble Dryer\",\"Microwave\",\"Kettle\"])\n",
        "# dfF = dfF.rename_axis('Index')\n",
        "# dfF.to_csv(\"no_features_baseline.csv\")"
      ],
      "metadata": {
        "id": "dfAQRXFrui9A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}